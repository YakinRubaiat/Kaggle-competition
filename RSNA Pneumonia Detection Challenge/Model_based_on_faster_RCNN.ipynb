{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport json # For import the model\nimport pydicom # To read dicom image\nimport math\nfrom imgaug import augmenters as iaa # For image augmention\nimport cv2 # To process img\nimport random # Generate random number to see img\nimport sys \nimport glob # Unix style pathname pattern expansion\nimport os\nfrom tqdm import tqdm \nimport base64\nfrom IPython.display import HTML",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "Data_Dir = '/kaggle/input/rsna-pneumonia-detection-challenge'\nRoot_Dir = '/kaggle/working'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6725de4f97a5890725f59e56e74f1c0b1e79b7e5"
      },
      "cell_type": "code",
      "source": "!git clone https://www.github.com/matterport/Mask_RCNN.git",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f830c4050708201ff0c272a114da4bc78734f04"
      },
      "cell_type": "code",
      "source": "cd ./working",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd3dd0d3201e1aaac6551070aa1dd8fd32e9799b"
      },
      "cell_type": "code",
      "source": "cd ./Mask_RCNN",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e075a510f295361bb27891ee1760babfbc02143"
      },
      "cell_type": "code",
      "source": "sys.path.append(os.path.join(Root_Dir, 'Mask_RCNN'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f72f36c8963b8cf283a7c1657086ada441030980"
      },
      "cell_type": "code",
      "source": "from mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4ca825e817cfd128fddd037578e932fb30d9d2fa"
      },
      "cell_type": "markdown",
      "source": "# Import Image"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a65a35d4efca41ba1e72829b7fd1ba60debc8d92"
      },
      "cell_type": "code",
      "source": "train_dicom_dir = os.path.join(Data_Dir, 'stage_1_train_images')\ntest_dicom_dir = os.path.join(Data_Dir, 'stage_1_test_images')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c36e5202f5b766257d4da920555917c8e5cbc977"
      },
      "cell_type": "code",
      "source": "!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1916367b630753e1c8f1e2f476c7ff258ec2753f"
      },
      "cell_type": "code",
      "source": "!ls -lh mask_rcnn_coco.h5",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ccae7503e463d0f4ba0ac628466b70307021be54"
      },
      "cell_type": "code",
      "source": "ImageNet_Weight_PATH = \"mask_rcnn_coco.h5\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7cf9f67a33bb8815326cf843a5395a6c2f134093"
      },
      "cell_type": "code",
      "source": "def get_dicom_fps(dicom_dir):\n    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n    return list(set(dicom_fps))\n\ndef parse_dataset(dicom_dir, anns): \n    image_fps = get_dicom_fps(dicom_dir)\n    image_annotations = {fp: [] for fp in image_fps}\n    for index, row in anns.iterrows(): \n        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n        image_annotations[fp].append(row)\n    return image_fps, image_annotations",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f562fd426d07fab5007d20586db689b937b0b28c"
      },
      "cell_type": "code",
      "source": "class DetectorConfig(Config):\n    \n    # Give the configuration a recognizable name  \n    NAME = 'pneumonia'\n    \n    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 8\n    \n    BACKBONE = 'resnet50'\n    \n    NUM_CLASSES = 2  # background + 1 pneumonia classes\n    \n    IMAGE_MIN_DIM = 256\n    IMAGE_MAX_DIM = 256\n    RPN_ANCHOR_SCALES = (32, 64, 128, 256)\n    TRAIN_ROIS_PER_IMAGE = 32\n    MAX_GT_INSTANCES = 3\n    DETECTION_MAX_INSTANCES = 3\n    DETECTION_MIN_CONFIDENCE = 0.7\n    DETECTION_NMS_THRESHOLD = 0.1\n\n    STEPS_PER_EPOCH = 200\n    \nconfig = DetectorConfig()\nconfig.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f2d246d0632e6d2af98d13606c1b367c647d3417"
      },
      "cell_type": "code",
      "source": "class DetectorDataset(utils.Dataset):\n    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n    \"\"\"\n\n    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n        super().__init__(self)\n        \n        # Add classes\n        self.add_class('pneumonia', 1, 'Lung Opacity')\n        \n        # add images \n        for i, fp in enumerate(image_fps):\n            annotations = image_annotations[fp]\n            self.add_image('pneumonia', image_id=i, path=fp, \n                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n            \n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path']\n\n    def load_image(self, image_id):\n        info = self.image_info[image_id]\n        fp = info['path']\n        ds = pydicom.read_file(fp)\n        image = ds.pixel_array\n        # If grayscale. Convert to RGB for consistency.\n        if len(image.shape) != 3 or image.shape[2] != 3:\n            image = np.stack((image,) * 3, -1)\n        return image\n\n    def load_mask(self, image_id):\n        info = self.image_info[image_id]\n        annotations = info['annotations']\n        count = len(annotations)\n        if count == 0:\n            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n            class_ids = np.zeros((1,), dtype=np.int32)\n        else:\n            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n            class_ids = np.zeros((count,), dtype=np.int32)\n            for i, a in enumerate(annotations):\n                if a['Target'] == 1:\n                    x = int(a['x'])\n                    y = int(a['y'])\n                    w = int(a['width'])\n                    h = int(a['height'])\n                    mask_instance = mask[:, :, i].copy()\n                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n                    mask[:, :, i] = mask_instance\n                    class_ids[i] = 1\n        return mask.astype(np.bool), class_ids.astype(np.int32)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1c46dbdcf03dee8c727722acd86bc3755e1fb65"
      },
      "cell_type": "code",
      "source": "!ls",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "069fb92a32f9fc25936a6d1328db54fdb3adb971"
      },
      "cell_type": "code",
      "source": "anns = pd.read_csv(os.path.join(Data_Dir, 'stage_1_train_labels.csv'))\nanns.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bfb863aba59760e54c8fbb15d359c7cb35fb705a"
      },
      "cell_type": "code",
      "source": "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d6659f31169c2af2d8348ca78ab3990382e73028"
      },
      "cell_type": "code",
      "source": "ORIG_SIZE = 1024\nimage_fps_list = list(image_fps)\nrandom.seed(42)\nrandom.shuffle(image_fps_list)\n\nval_size = 2100\nimage_fps_val = image_fps_list[:val_size]\nimage_fps_train = image_fps_list[val_size:]\n\nprint(len(image_fps_train), len(image_fps_val))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93e1be1f38417f7e0f8061a79f54ce77e631c633"
      },
      "cell_type": "code",
      "source": "dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\ndataset_train.prepare()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4bfa8ef5d66a4d9d336f4000fe903e7fb3f015bb"
      },
      "cell_type": "code",
      "source": "dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\ndataset_val.prepare()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "69f7eb4004b46d4231700f1a374f2a28684cf6fb"
      },
      "cell_type": "markdown",
      "source": "# Augmentation. [Details](http://https://github.com/aleju/imgaug)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "085e87c5358cb0e7d7e31d7328f1878119c9dcba"
      },
      "cell_type": "code",
      "source": "# Image augmentation (light but constant)\naugmentation = iaa.Sequential([\n    iaa.OneOf([ ## geometric transform\n        iaa.Affine(\n            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.02)},\n            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n            rotate=(-2, 2),\n            shear=(-1, 1),\n        ),\n        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n    ]),\n    iaa.OneOf([ ## brightness or contrast\n        iaa.Multiply((0.9, 1.1)),\n        iaa.ContrastNormalization((0.9, 1.1)),\n    ]),\n    iaa.OneOf([ ## blur or sharpen\n        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n        iaa.Sharpen(alpha=(0.0, 0.1)),\n    ]),\n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce6805bd14afe5e92c55a8c2c45d9b0f84d4c677"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a4e4dc995277cb3bbc6c00eef9d141ed98973bd"
      },
      "cell_type": "code",
      "source": "class InferenceConfig(DetectorConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(mode='training', \n                          config=config,\n                          model_dir=Root_Dir)\n\n# Load trained weights (fill in path to trained weights here)\n#assert model_path != \"\", \"Provide path to trained weights\"\nmodel_path = '/kaggle/input/fork-v8-henrique-s-model-w-randomly-higher-score/pneumonia20181003T1552/mask_rcnn_pneumonia_0015.h5'\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a42df34c7b9e2bd9cc4c0cad059a208b2bdf5bb"
      },
      "cell_type": "code",
      "source": "model = modellib.MaskRCNN(mode='training', config=config, model_dir=Root_Dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ff8bb3af687f9b9e08e69d2db4fdfaedd05db1a"
      },
      "cell_type": "code",
      "source": "model.load_weights(ImageNet_Weight_PATH, by_name=True, exclude=[\n    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n    \"mrcnn_bbox\", \"mrcnn_mask\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b35e9a10efde66921c0b5ecdacc2473b48fbadc4"
      },
      "cell_type": "code",
      "source": "LEARNING_RATE = 0.001\n\n# Train Mask-RCNN Model \nimport warnings \nwarnings.filterwarnings(\"ignore\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ecb9fc63ca6a75a15e345f5dd0376353d9a96c2d"
      },
      "cell_type": "code",
      "source": "%%time\n## train heads with higher lr to speedup the learning\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE*2,\n            epochs=2,\n            layers='heads',\n            augmentation=None)  ## no need to augment yet\nhistory = model.keras_model.history.history.copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e60c359de4fdea495a8801e2f3f8e9159df36ff"
      },
      "cell_type": "code",
      "source": "%%time\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE,\n            epochs=20,\n            layers='all',\n            augmentation=augmentation)\n#news = model.keras_model.history.history\n#for k in news: history[k] = history[k] + news[k]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f2079a8166e09e0899093bd02189b57ad4bf76e"
      },
      "cell_type": "code",
      "source": "history = model.keras_model.history.history.copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8797866c0eb23bf49dbc2bf95f1f6ccb77a8b252"
      },
      "cell_type": "code",
      "source": "model = modellib.MaskRCNN(mode='training', \n                          config=config,\n                          model_dir=Root_Dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee27f258d5bb51b3aa7a7c06ab2cce89d9133672"
      },
      "cell_type": "code",
      "source": "model.load_weights(model_path, by_name=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "89f7db8fbe6d02a9b59caa3aba4782a69f2366ce"
      },
      "cell_type": "code",
      "source": "%%time\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE/5,\n            epochs=30,\n            layers='all',\n            augmentation=augmentation)\nnews = model.keras_model.history.history\nfor k in news: history[k] = history[k] + news[k]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b619be8d1760500bc6d399f214787f8dd2f10060"
      },
      "cell_type": "code",
      "source": "epochs = range(1,len(next(iter(history.values())))+1)\npd.DataFrame(history, index=epochs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0fb3bee7f5deabdc8ba8ca7dda63be6f68724fd"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(15,5))\nplt.subplot(111)\nplt.plot(epochs, history[\"loss\"], label=\"Train loss\")\nplt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f35808966ae4295233fc5b3628aad00ae0b2a09"
      },
      "cell_type": "code",
      "source": "dir_names = next(os.walk(model.model_dir))[1]\nkey = config.NAME.lower()\ndir_names = filter(lambda f: f.startswith(key), dir_names)\ndir_names = sorted(dir_names)\n\nif not dir_names:\n    import errno\n    raise FileNotFoundError(\n        errno.ENOENT,\n        \"Could not find model directory under {}\".format(self.model_dir))\n    \nfps = []\n# Pick last directory\nfor d in dir_names: \n    dir_name = os.path.join(model.model_dir, d)\n    # Find the last checkpoint\n    checkpoints = next(os.walk(dir_name))[2]\n    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n    checkpoints = sorted(checkpoints)\n    if not checkpoints:\n        print('No weight files in {}'.format(dir_name))\n    else:\n        checkpoint = os.path.join(dir_name, checkpoints[-1])\n        fps.append(checkpoint)\n\nmodel_path = sorted(fps)[-1]\nprint('Found model {}'.format(model_path))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7283de890326174b402669f838ffa90422b5ed4b"
      },
      "cell_type": "code",
      "source": "class InferenceConfig(DetectorConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(mode='inference', \n                          config=inference_config,\n                          model_dir=Root_Dir)\n\n# Load trained weights (fill in path to trained weights here)\nassert model_path != \"\", \"Provide path to trained weights\"\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75345e9f8b485e8782af7f4c2392926acdea65d7"
      },
      "cell_type": "code",
      "source": "test_image_fps = get_dicom_fps(test_dicom_dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f66a7e87846738ad6a94002deb986bc7bc891765"
      },
      "cell_type": "code",
      "source": "def predict(image_fps, filepath='submission.csv', min_conf=0.95):\n    # assume square image\n    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n    #resize_factor = ORIG_SIZE\n    with open(filepath, 'w') as file:\n        file.write(\"patientId,PredictionString\\n\")\n\n        for image_id in tqdm(image_fps):\n            ds = pydicom.read_file(image_id)\n            image = ds.pixel_array\n            # If grayscale. Convert to RGB for consistency.\n            if len(image.shape) != 3 or image.shape[2] != 3:\n                image = np.stack((image,) * 3, -1)\n            image, window, scale, padding, crop = utils.resize_image(\n                image,\n                min_dim=config.IMAGE_MIN_DIM,\n                min_scale=config.IMAGE_MIN_SCALE,\n                max_dim=config.IMAGE_MAX_DIM,\n                mode=config.IMAGE_RESIZE_MODE)\n\n            patient_id = os.path.splitext(os.path.basename(image_id))[0]\n\n            results = model.detect([image])\n            r = results[0]\n\n            out_str = \"\"\n            out_str += patient_id\n            out_str += \",\"\n            assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n            if len(r['rois']) == 0:\n                pass\n            else:\n                num_instances = len(r['rois'])\n\n                for i in range(num_instances):\n                    if r['scores'][i] > min_conf:\n                        out_str += ' '\n                        out_str += str(round(r['scores'][i], 2))\n                        out_str += ' '\n\n                        # x1, y1, width, height\n                        x1 = r['rois'][i][1]\n                        y1 = r['rois'][i][0]\n                        width = r['rois'][i][3] - x1\n                        height = r['rois'][i][2] - y1\n                        bboxes_str = \"{} {} {} {}\".format(x1*resize_factor, y1*resize_factor, \\\n                                                           width*resize_factor, height*resize_factor)\n                        out_str += bboxes_str\n\n            file.write(out_str+\"\\n\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7d98f5edba2b747728bec0601524773b56b62f4"
      },
      "cell_type": "code",
      "source": "submission_fp = os.path.join(Root_Dir, 'submission.csv')\npredict(test_image_fps, filepath=submission_fp)\nprint(submission_fp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd930f43df2a91403cab108727084cca7e1e16c5"
      },
      "cell_type": "code",
      "source": "def create_download_link(df, title = \"Download CSV file\", filename = \"RSNA_DataSet.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75f08f6f0cddcefffee869c6d67cd33737a90907"
      },
      "cell_type": "code",
      "source": "cd ./working",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d38fc23411d4231506f06e72317c2f35615cfc53"
      },
      "cell_type": "code",
      "source": "csv = pd.DataFrame.from_csv(\"submission.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d6a6bbf37c742848c0d80dad8b1ce29d338cf25a"
      },
      "cell_type": "code",
      "source": "create_download_link(csv)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}